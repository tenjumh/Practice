{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기폰 패키지\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from html_table_parser import parser_functions as parser\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀레니움(selenium)으로 브라우저를 컨트를하기 위해서는 webdriver를 설치해야 한다\n",
    "# 구글크롬은 chromedriver로 검색하면 exe파일을 다운로드 할 수 있다.\n",
    "# webdriver 설치 위치를 정의한다.\n",
    "browser = webdriver.Chrome('C:\\Program Files (x86)\\Google\\Chrome\\Application\\chromedriver')\n",
    "\n",
    "def crawling(url):\n",
    "    # 셀레니움(selenium)으로 브라우저를 컨트를하기 위해서는 webdriver를 설치해야 한다\n",
    "    # 구글크롬은 chromedriver로 검색하면 exe파일을 다운로드 할 수 있다.\n",
    "    # webdriver 설치 위치를 정의한다.\n",
    "    browser = webdriver.Chrome('C:\\Program Files (x86)\\Google\\Chrome\\Application\\chromedriver')\n",
    "    # 불러오고자하는 url을 .get으로 호출한다.\n",
    "    browser.get(url)\n",
    "    \n",
    "    # page_source파라미터를 이용하면 HTML정보를 가지고 온다.\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')   # 뷰티풀숩으로 HTML을 파싱하고 필요한 데이터 수집\n",
    "    table_tags = soup.find_all(\"table\")   # find_all함수를 이용하면, TABLE태그로 지정된 곳만 뽑아서, 배열 형태로 저장\n",
    "    table = table_tags[0]    # html상에서 table 순서, 첫번째 테이블 가지고 와야 함.\n",
    "    p=parser.make2d(table)\n",
    "\n",
    "    df_total=pd.DataFrame(p[1:],columns=p[0])    # 데이터 프레임으로 저장\n",
    "\n",
    "    num = soup.find_all(\"button\")[5].text   # 5번째 button에 페이지수 정보가 있음\n",
    "    for j in range(1, int(num)):\n",
    "        btn = browser.find_element_by_class_name('paginationWidget-next')\n",
    "        btn.click()     # 버튼 클릭\n",
    "        time.sleep(5)\n",
    "\n",
    "        # 2페이지 이후 데이터 병합\n",
    "        html = browser.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        table_tags = soup.find_all(\"table\")\n",
    "        table = table_tags[0]\n",
    "        p = parser.make2d(table)\n",
    "\n",
    "        df = pd.DataFrame(p[1:], columns=p[0])\n",
    "        df_total = pd.concat([df_total, df], 0)\n",
    "        \n",
    "    return df_total\n",
    "        # 엑셀로 다운로드\n",
    "        # df_total.to_excel(\"test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_url = [\"http://mlb.mlb.com/stats/sortable.jsp?c_id=mlb#elem=%5Bobject+Object%5D&tab_level=child&click_text=Sortable+Player+hitting&game_type='R'&season=2019&season_type=ANY&league_code='MLB'&sectionType=sp&statType=hitting&page=1&ts=1580532864437&playerType=ALL\",\n",
    "\"http://mlb.mlb.com/stats/sortable.jsp?c_id=mlb#elem=%5Bobject+Object%5D&tab_level=child&click_text=Sortable+Player+fielding&game_type='R'&season=2019&season_type=ANY&league_code='MLB'&sectionType=sp&statType=fielding&page=1&ts=1580539033522&playerType=ALL\"]\n",
    "\n",
    "df_total_hit_2012 = crawling(list_url[0])\n",
    "df_total_field_2012 = crawling(list_url[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼 rename\n",
    "df_total_hit_2012 = df_total_hit_2012.rename(columns={'RK':'RK', 'Player':'Player', 'Team':'Team', \n",
    "                                            '':'del', '▲':'del2', 'Pos':'Pos', 'G▼':'G', 'AB▼':'AB', 'R▼':'R',\n",
    "                                            'H▼':'H', '2B▼':'2B', '3B▼':'3B', 'HR▼':'HR',\n",
    "                                            'RBI▼':'RBI', 'BB▼':'BB', 'SO▼':'SO', 'SB▼':'SB',\n",
    "                                            'CS▼':'CS', 'AVG▼':'AVG', 'OBP▼':'OBP',\n",
    "                                            'SLG▼':'SLG', 'OPS▼':'OPS', 'IBB▼':'IBB',\n",
    "                                            'HBP▼':'HBP', 'SAC▼':'SAC', 'SF▼':'SF', \n",
    "                                            'TB▼':'TB', 'XBH▼':'XBH', 'GDP▼':'GDP',\n",
    "                                            'GO▼':'GO', 'AO▼':'AO', 'GO_AO▼':'GO_AO',\n",
    "                                            'NP▼':'NP', 'PA▼':'PA'})\n",
    "df_total_field_2012 = df_total_field_2012.rename(columns={'RK':'RK', 'Player':'Player', 'Team':'Team', '':'del',\n",
    "                                            '▲':'del2', 'Pos':'Pos', 'G▼':'G', 'GS▼':'GS',\n",
    "                                            'INN▼':'INN', 'TC▼':'TC', 'PO▼':'PO', 'A▼':'A',\n",
    "                                            'E▼':'E', 'DP▼':'DP', 'SB▼':'SB', 'CS▼':'CS',\n",
    "                                            'SBPCT▲':'SBPCT', 'PB▼':'PB', 'C_WP▼':'C_WP',\n",
    "                                            'FPCT▼':'FPCT', 'RF▼':'RF'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_data = df_total_hit_2012.to_excel(\"./backup/df_total_hit.xlsx\")\n",
    "field_data = df_total_field_2012.to_excel(\"./backup/df_total_field.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
